{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Accidental Drug Death Data\n",
    "\n",
    "Heroin and opioid painkillers have led to increasing overdose death for several years. I've had trouble finding good open data about it.\n",
    "\n",
    "I was impressed by [this page on the Connecticut data portal](https://data.ct.gov/view/ecj5-r2i9) which takes data of the sort which I'd not had much luck finding for Illinois and presents it with some good overview graphs.\n",
    "\n",
    "It also seemed like a better dataset for looking at pivot tables than the one I started with, so I decided to run through some exercises with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from Socrata\n",
    "\n",
    "First we need the data. Downloading a file and moving it around is inelegant, so let's see if we can get it over the web. This [web page from Socrata](https://dev.socrata.com/consumers/examples/data-visualization-with-python.html) clued me to the fact that the SODA API provides perfect input to a dataframe. \n",
    "\n",
    "The [SODA API docs](https://dev.socrata.com/docs/endpoints.html) show how to get the `pandas`-friendly version of the original URL, and once you know, the pattern is pretty straightforward. We follow the link from the view linked above to the [original data source](https://data.ct.gov/Health-and-Human-Services/Accidental-Drug-Related-Deaths-January-2012-Sept-2/rybz-nyjw) and \n",
    "  \n",
    "`https://data.ct.gov/Health-and-Human-Services/Accidental-Drug-Related-Deaths-January-2012-Sept-2/rybz-nyjw`\n",
    "\n",
    "becomes\n",
    "\n",
    "`https://data.ct.gov/resource/rybz-nyjw.json`\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib2 import urlopen\n",
    "\n",
    "data_url = 'https://data.ct.gov/resource/rybz-nyjw.json'\n",
    "df = pd.read_json(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, when I ran the command above, I got\n",
    "\n",
    "```URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:581)>```\n",
    "\n",
    "[Stack Overflow to the rescue](http://stackoverflow.com/a/28048260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1000 rows\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "response = urlopen(data_url,context=ctx)\n",
    "df = pd.read_json(response)\n",
    "\n",
    "print \"Read {} rows\".format(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Securing the perimeter\n",
    "\n",
    "Before you get too deep into a dataset, you need to check it out and make sure there aren't any gotchas hiding. Ideally, we find a data dictionary for a dataset. Truth be told, we often skate by it and just use inference, especially since often there isn't one anyway! But remember that before you make any public pronouncements about finding the data, you really ought to make sure that the columns and values mean what you guessed they mean.\n",
    "\n",
    "There's no sign of a full data dictionary for this dataset, although there is some useful information in the [Socrata description page](https://data.ct.gov/Health-and-Human-Services/Accidental-Drug-Related-Deaths-January-2012-Sept-2/rybz-nyjw/about), specifically about how deaths involving heroin and morphine are documented.\n",
    "\n",
    "So, whether we are skipping the data dictionary out of laziness or reality, data analysts develop some routine checks when they start with a dataset. In 2014, Hilary Mason solicited people for their checks with [a tweet](https://twitter.com/hmason/statuses/476905839035305984), and Jeff Leek [knit them into a blog post](http://simplystatistics.org/2014/06/13/what-i-do-when-i-get-a-new-data-set-as-told-through-tweets/)\n",
    "\n",
    "I always like to start with `df.head()` because it's easy to scan and see patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>amphet</th>\n",
       "      <th>any_opioid</th>\n",
       "      <th>benzo_s</th>\n",
       "      <th>casenumber</th>\n",
       "      <th>coc</th>\n",
       "      <th>date</th>\n",
       "      <th>death_city</th>\n",
       "      <th>death_county</th>\n",
       "      <th>death_state</th>\n",
       "      <th>...</th>\n",
       "      <th>morphine_not_heroin</th>\n",
       "      <th>other</th>\n",
       "      <th>oxyc</th>\n",
       "      <th>oxym</th>\n",
       "      <th>race</th>\n",
       "      <th>residence_city</th>\n",
       "      <th>residence_county</th>\n",
       "      <th>residence_state</th>\n",
       "      <th>sex</th>\n",
       "      <th>tramad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-10038</td>\n",
       "      <td>Y</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>Southington</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Southington</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-10152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-10196</td>\n",
       "      <td>Y</td>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>CT</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>15-10202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>New London</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPIOID NOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Waterford</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>CT</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-10208</td>\n",
       "      <td>Y</td>\n",
       "      <td>2015-06-20</td>\n",
       "      <td>New London</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hispanic, White</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>CT</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age amphet any_opioid benzo_s casenumber  coc       date   death_city  \\\n",
       "0   52    NaN        NaN     NaN   15-10038    Y 2015-06-16  Southington   \n",
       "1   26    NaN          Y     NaN   15-10152  NaN 2015-06-19   Manchester   \n",
       "2   50    NaN          Y     NaN   15-10196    Y 2015-06-19      Danbury   \n",
       "3   42    NaN          Y       Y   15-10202  NaN 2015-06-19   New London   \n",
       "4   42    NaN          Y     NaN   15-10208    Y 2015-06-20   New London   \n",
       "\n",
       "  death_county death_state  ...   morphine_not_heroin       other oxyc oxym  \\\n",
       "0     HARTFORD          CT  ...                   NaN         NaN  NaN  NaN   \n",
       "1     HARTFORD          CT  ...                   NaN         NaN  NaN  NaN   \n",
       "2    FAIRFIELD          CT  ...                   NaN         NaN  NaN  NaN   \n",
       "3   NEW LONDON          CT  ...                   NaN  OPIOID NOS  NaN  NaN   \n",
       "4   NEW LONDON          CT  ...                   NaN         NaN  NaN  NaN   \n",
       "\n",
       "              race residence_city residence_county residence_state     sex  \\\n",
       "0            White    Southington         HARTFORD              CT    Male   \n",
       "1            White     Manchester         HARTFORD              CT    Male   \n",
       "2            White        Danbury        FAIRFIELD              CT    Male   \n",
       "3            White      Waterford       NEW LONDON              CT  Female   \n",
       "4  Hispanic, White        Lebanon       NEW LONDON              CT    Male   \n",
       "\n",
       "  tramad  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of `NaN` values, blanks in the original dataset but, one would infer, they could also be converted to `N` values if null/`NaN` is going to be a problem, but they shouldn't make you nervous.\n",
    "\n",
    "I also like to use `df.describe()` early on. `describe()` gives different summaries for numeric and non-numeric columns. By default, `df.describe()` only describes numeric columns. There's only one in this dataset (`age`), so the default isn't super helpful. We can ask for everything with `df.describe(include='all')`. That's fine, and maybe easiest to remember, but it makes a lot of `NaN` values. So let's do it in a couple of steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.419991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age\n",
       "count  1000.000000\n",
       "mean     41.491000\n",
       "std      12.419991\n",
       "min      14.000000\n",
       "25%      31.000000\n",
       "50%      42.000000\n",
       "75%      51.000000\n",
       "max      81.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Earlier we saw (with `len(df)`) that there are 1000 rows, so we can see that there are no missing values for `age`. (I should note that the nice round 1000 rows has also set off my data \"spidey sense\" -- I have a hunch that we just got one page of results -- but we can defer that while we get a general sense of the data.\n",
    "\n",
    "Let's see what datatypes we have in here, so we can use `describe` to summarize the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object            28\n",
       "datetime64[ns]     1\n",
       "int64              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK: 28 `object` -- or for regular people, string values -- and one `datetime`. \n",
    "Anyway, let's look at each of those. Since there's only one date, let's look at that first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-07-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2014-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2015-09-30 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date\n",
       "count                  1000\n",
       "unique                  488\n",
       "top     2015-07-05 00:00:00\n",
       "freq                      7\n",
       "first   2014-01-02 00:00:00\n",
       "last    2015-09-30 00:00:00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amphet</th>\n",
       "      <th>any_opioid</th>\n",
       "      <th>benzo_s</th>\n",
       "      <th>casenumber</th>\n",
       "      <th>coc</th>\n",
       "      <th>death_city</th>\n",
       "      <th>death_county</th>\n",
       "      <th>death_state</th>\n",
       "      <th>deathloc</th>\n",
       "      <th>etoh</th>\n",
       "      <th>...</th>\n",
       "      <th>morphine_not_heroin</th>\n",
       "      <th>other</th>\n",
       "      <th>oxyc</th>\n",
       "      <th>oxym</th>\n",
       "      <th>race</th>\n",
       "      <th>residence_city</th>\n",
       "      <th>residence_county</th>\n",
       "      <th>residence_state</th>\n",
       "      <th>sex</th>\n",
       "      <th>tramad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26</td>\n",
       "      <td>463</td>\n",
       "      <td>285</td>\n",
       "      <td>1000</td>\n",
       "      <td>235</td>\n",
       "      <td>1000</td>\n",
       "      <td>846</td>\n",
       "      <td>508</td>\n",
       "      <td>1000</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>127</td>\n",
       "      <td>152</td>\n",
       "      <td>23</td>\n",
       "      <td>997</td>\n",
       "      <td>966</td>\n",
       "      <td>482</td>\n",
       "      <td>492</td>\n",
       "      <td>1000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>194</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>15-12337</td>\n",
       "      <td>Y</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>CT</td>\n",
       "      <td>{u'latitude': u'41.765775', u'needs_recoding':...</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td></td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>White</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>CT</td>\n",
       "      <td>Male</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>25</td>\n",
       "      <td>462</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>104</td>\n",
       "      <td>248</td>\n",
       "      <td>508</td>\n",
       "      <td>56</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>151</td>\n",
       "      <td>23</td>\n",
       "      <td>826</td>\n",
       "      <td>61</td>\n",
       "      <td>142</td>\n",
       "      <td>481</td>\n",
       "      <td>732</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amphet any_opioid benzo_s casenumber  coc death_city death_county  \\\n",
       "count      26        463     285       1000  235       1000          846   \n",
       "unique      2          2       1       1000    2        149            8   \n",
       "top         Y          Y       Y   15-12337    Y   Hartford    NEW HAVEN   \n",
       "freq       25        462     285          1  225        104          248   \n",
       "\n",
       "       death_state                                           deathloc etoh  \\\n",
       "count          508                                               1000  237   \n",
       "unique           1                                                224    2   \n",
       "top             CT  {u'latitude': u'41.765775', u'needs_recoding':...    Y   \n",
       "freq           508                                                 56  235   \n",
       "\n",
       "        ...   morphine_not_heroin other oxyc oxym   race residence_city  \\\n",
       "count   ...                    11   127  152   23    997            966   \n",
       "unique  ...                     2    44    2    1      8            194   \n",
       "top     ...                     Y          Y    Y  White      Waterbury   \n",
       "freq    ...                    10    17  151   23    826             61   \n",
       "\n",
       "       residence_county residence_state   sex tramad  \n",
       "count               482             492  1000     22  \n",
       "unique               18               7     2      1  \n",
       "top           NEW HAVEN              CT  Male      Y  \n",
       "freq                142             481   732     22  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
